{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://colab.research.google.com/github/davide-gurrieri/timeseries-forecasting/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{},"source":["### Settings"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["COLAB = False\n","FIRST_RUN = True\n","SEED = 42\n","PLOT = False\n","MULTIPLE_MODELS = True\n","VAL_SPLIT = 0.1\n","PREVIOUS_SPLIT = True\n","WINDOW = 100\n","STRIDE = 10\n","TELESCOPE = 9\n","CUT = False # cut the initial timestamps of the timeseries in order to mantain the last N_TIME_STAMPS\n","N_TIME_STAMPS = 209 # WINDOW + TELESCOPE # number of time stamps to mantain\n","\n","BATCH_SIZE = 128\n","EPOCHS = 200"]},{"cell_type":"markdown","metadata":{},"source":["### Colab"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["if COLAB:\n","    if FIRST_RUN:\n","        ## Clone the private repository in Colab\n","        TOKEN = \"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\"\n","        REPO_URL= \"github.com/davide-gurrieri/timeseries-forecasting.git\"\n","        USER_NAME = \"davide-gurrieri\"\n","        USER_EMAIL = \"gurrieri99@gmail.com\"\n","\n","        !git clone --branch main https://oauth2:$TOKEN@$REPO_URL\n","        %cd timeseries-forecasting/\n","        !git remote set-url origin  https://oauth2:$TOKEN@$REPO_URL\n","        !git config user.name $USER_NAME\n","        !git config user.email $USER_EMAIL\n","        %cd ..\n","        \n","        # Import the data from the drive\n","        from google.colab import drive\n","        drive.mount('/content/drive')\n","        # Copy the data from the drive to the local repository folder\n","        %cp \"drive/MyDrive/[2023-2024] AN2DL/Homework 2/training_dataset.zip\" \"timeseries-forecasting/data/\"\n","        # Unzip the data\n","        !unzip timeseries-forecasting/data/training_dataset.zip -d timeseries-forecasting/data/\n","        # Remove the zip file\n","        !rm timeseries-forecasting/data/training_dataset.zip\n","        %cd timeseries-forecasting/\n","        \n","        # Install the requirements\n","        # !pip install keras-cv\n","    else:\n","        %cd timeseries-forecasting/"]},{"cell_type":"markdown","metadata":{"id":"ap3o8JayfgEM"},"source":["### Import libraries"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"aR-w0eZ-ABIT"},"outputs":[],"source":["# Fix randomness and hide warnings\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","os.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n","\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","\n","import numpy as np\n","np.random.seed(SEED)\n","\n","import logging\n","\n","import random\n","random.seed(SEED)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1701344026814,"user":{"displayName":"Eugenio Lomurno","userId":"00192456819128711881"},"user_tz":-60},"id":"e06wPZJbADcv","outputId":"b45fbe1e-e9a9-47b7-ca25-0383365a47c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.14.0\n"]}],"source":["# Import tensorflow\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","tf.autograph.set_verbosity(0)\n","tf.get_logger().setLevel(logging.ERROR)\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","tf.random.set_seed(SEED)\n","tf.compat.v1.set_random_seed(SEED)\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"fN6wKImkADfL"},"outputs":[],"source":["import pandas as pd\n","import seaborn as sns\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","plt.rc('font', size=16)\n","from sklearn.preprocessing import MinMaxScaler"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from utils import *"]},{"cell_type":"markdown","metadata":{},"source":["### Data processing"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["(48000, 2776)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["data = np.load(\"data/training_data.npy\")\n","data.shape"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["data = data.astype(np.float32)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Unique categories:\n","['A' 'B' 'C' 'D' 'E' 'F']\n"]}],"source":["categories = np.load(\"data/categories.npy\")\n","categories.shape\n","print(\"Unique categories:\")\n","print(np.unique(categories))"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[2325 2776]\n"," [2325 2776]\n"," [2325 2776]\n"," [2712 2776]]\n","Min and max start time:  0 2752\n","Min and max end time:  2776 2776\n"]}],"source":["valid_periods = np.load(\"data/valid_periods.npy\")\n","valid_periods.shape\n","print(valid_periods[0:4,])\n","print(\"Min and max start time: \", min(valid_periods[:,0]), max(valid_periods[:,0]))\n","print(\"Min and max end time: \", min(valid_periods[:,1]), max(valid_periods[:,1]))"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean length of the time series:  198.30022916666667\n"]}],"source":["mean_len = np.mean(valid_periods[:,1] - valid_periods[:,0])\n","print(\"Mean length of the time series: \", mean_len)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Better to save the image and open the pdf to see all the details\n","if PLOT:\n","    plot_matrix(data, save=True, show=True)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Better to save the images and open pdfs to see all the details\n","if PLOT:\n","    for category in np.unique(categories):\n","        plot_matrix(data[categories == category], save=True, show=True, name=category)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of rows for each category:\n","A 5728\n","B 10987\n","C 10017\n","D 10016\n","E 10975\n","F 277\n"]}],"source":["# count the number of rows in each category\n","print(\"Number of rows for each category:\")\n","for category in np.unique(categories):\n","    print(category, np.sum(categories == category))"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["if PLOT:\n","    plot_time_series(data, categories, category=\"A\", n=5)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# cut the data\n","if CUT:\n","    start_time_index = len(data[0]) - N_TIME_STAMPS\n","    data = data[:,start_time_index:]\n","    valid_periods = valid_periods - start_time_index\n","    # set each element of  valid_periods[:,0] to 0 if it is negative\n","    valid_periods[:,0] = np.maximum(valid_periods[:,0], 0)\n","    if PLOT:\n","        plot_matrix(data)\n","    print(data.shape)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# split the data into train and validation\n","if PREVIOUS_SPLIT:\n","    X_train_raw, X_val_raw, categories_train, categories_val, valid_periods_train, valid_periods_val = train_test_split(data, categories, valid_periods, stratify=categories, test_size=VAL_SPLIT, random_state=SEED)\n","    X_train_raw.shape, X_val_raw.shape, categories_train.shape, categories_val.shape, valid_periods_train.shape, valid_periods_val.shape"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# one model for each class\n","if MULTIPLE_MODELS:\n","    if PREVIOUS_SPLIT:\n","        X_train_list, y_train_list = build_multiclass_sequences(X_train_raw, valid_periods_train, categories_train, WINDOW, STRIDE, TELESCOPE)\n","        X_val_list, y_val_list = build_multiclass_sequences(X_val_raw, valid_periods_val, categories_val, WINDOW, STRIDE, TELESCOPE)\n","    else:\n","        X_train_list, y_train_list = build_multiclass_sequences(data, valid_periods, categories, WINDOW, STRIDE, TELESCOPE)\n","else:\n","    if PREVIOUS_SPLIT:\n","        X_train, y_train = build_sequences(X_train_raw, valid_periods_train, WINDOW, STRIDE, TELESCOPE)\n","        X_val, y_val = build_sequences(X_val_raw, valid_periods_val, WINDOW, STRIDE, TELESCOPE)\n","        print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n","    else:\n","        X_train, y_train = build_sequences(data, valid_periods, WINDOW, STRIDE, TELESCOPE)\n","        print(X_train.shape, y_train.shape)\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# inspect_multivariate(X_train, y_train, TELESCOPE, idx=0, n=5)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["((100, 1), (9, 1))"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["input_shape = X_train.shape[1:] if not MULTIPLE_MODELS else X_train_list[0].shape[1:]\n","output_shape = y_train.shape[1:] if not MULTIPLE_MODELS else y_train_list[0].shape[1:]\n","input_shape, output_shape"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["def learning_rate_schedule(epoch, lr):\n","    if epoch < 15:\n","        return lr  # No change for the first 10 epochs\n","    else:\n","        return lr * 0.8  # Decrease the learning rate by a factor (e.g., 0.8) after the 15th epoch"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# Must be WINDOW > TELESCOPE\n","def build_CONV_LSTM_model(input_shape, output_shape):\n","    # Ensure the input time steps are at least as many as the output time steps\n","    assert input_shape[0] >= output_shape[0], \"For this exercise we want input time steps to be >= of output time steps\"\n","\n","    # Define the input layer with the specified shape\n","    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n","\n","    # Add a Bidirectional LSTM layer with 64 units\n","    x = tfkl.Bidirectional(tfkl.LSTM(128, return_sequences=True, name='lstm'), name='bidirectional_lstm')(input_layer)\n","\n","    # Add a 1D Convolution layer with 128 filters and a kernel size of 3\n","    x = tfkl.Conv1D(256, 3, padding='same', activation='relu', name='conv')(x)\n","\n","    # Add a final Convolution layer to match the desired output shape\n","    output_layer = tfkl.Conv1D(output_shape[1], 3, padding='same', name='output_layer')(x)\n","\n","    # Calculate the size to crop from the output to match the output shape\n","    crop_size = output_layer.shape[1] - output_shape[0]\n","\n","    # Crop the output to the desired length\n","    output_layer = tfkl.Cropping1D((0, crop_size), name='cropping')(output_layer)\n","\n","    # Construct the model by connecting input and output layers\n","    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='CONV_LSTM_model')\n","\n","    # Compile the model with Mean Squared Error loss and Adam optimizer\n","    model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam())\n","\n","    return model"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# Must be WINDOW > TELESCOPE\n","def build_CONV_LSTM_model2(input_shape, output_shape):\n","    # Ensure the input time steps are at least as many as the output time steps\n","    assert input_shape[0] >= output_shape[0], \"For this exercise we want input time steps to be >= of output time steps\"\n","\n","    # Define the input layer with the specified shape\n","    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n","\n","    # Add a Bidirectional LSTM layer with 64 units\n","    x = tfkl.Bidirectional(tfkl.LSTM(8, return_sequences=True, name='lstm'), name='bidirectional_lstm')(input_layer)\n","\n","    # Add a 1D Convolution layer with 128 filters and a kernel size of 3\n","    x = tfkl.Conv1D(64, 3, padding='same', activation='relu', name='conv1')(x)\n","\n","    x = tfkl.Conv1D(32, 3, padding='same', activation='relu', name='conv2')(x)\n","\n","    x = tfkl.Conv1D(16, 3, padding='same', activation='relu', name='conv3')(x)\n","\n","    # Add a final Convolution layer to match the desired output shape\n","    output_layer = tfkl.Conv1D(output_shape[1], 3, padding='same', name='output_layer')(x)\n","\n","    # Calculate the size to crop from the output to match the output shape\n","    crop_size = output_layer.shape[1] - output_shape[0]\n","\n","    # Crop the output to the desired length\n","    output_layer = tfkl.Cropping1D((0, crop_size), name='cropping')(output_layer)\n","\n","    # Construct the model by connecting input and output layers\n","    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='CONV_LSTM_model')\n","\n","    # Compile the model with Mean Squared Error loss and Adam optimizer\n","    model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if MULTIPLE_MODELS:\n","    models = []\n","    histories = []\n","    for i in range(6):\n","        models.append(build_CONV_LSTM_model2(input_shape, output_shape))\n","        history = models[i].fit(\n","            x = X_train_list[i],\n","            y = y_train_list[i],\n","            batch_size = BATCH_SIZE,\n","            epochs = EPOCHS,\n","            validation_split = VAL_SPLIT if not PREVIOUS_SPLIT else 0,\n","            validation_data = (X_val_list[i], y_val_list[i]) if PREVIOUS_SPLIT else None,\n","            callbacks = [\n","                tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=12, restore_best_weights=True),\n","                tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, factor=0.1, min_lr=1e-5)\n","            ]\n","        ).history\n","        histories.append(history)\n","else:\n","    model = build_CONV_LSTM_model2(input_shape, output_shape)\n","    model.summary()\n","    tfk.utils.plot_model(model, expand_nested=True, show_shapes=True)\n","    \n","    history = model.fit(\n","        x = X_train,\n","        y = y_train,\n","        batch_size = BATCH_SIZE,\n","        epochs = EPOCHS,\n","        validation_split = VAL_SPLIT if not PREVIOUS_SPLIT else 0,\n","        validation_data = (X_val, y_val) if PREVIOUS_SPLIT else None,\n","        callbacks = [\n","            tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=12, restore_best_weights=True),\n","            tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, factor=0.1, min_lr=1e-5)\n","        ]\n","    ).history"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# save\n","if MULTIPLE_MODELS:\n","    for i in range(6):\n","        models[i].save(\"models/model_\"+str(i))\n","else:\n","    model.save(\"models/model\")"]},{"cell_type":"markdown","metadata":{},"source":["### Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if not MULTIPLE_MODELS:\n","    predictions = model.predict(X_val, verbose=0)\n","    mean_squared_error = tfk.metrics.mean_squared_error(y_train.flatten(), predictions.flatten()).numpy()\n","print(f\"Mean Squared Error: {mean_squared_error}\")\n","    "]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
