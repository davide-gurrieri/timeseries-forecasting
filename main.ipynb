{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://colab.research.google.com/github/davide-gurrieri/timeseries-forecasting/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{},"source":["### Settings"]},{"cell_type":"markdown","metadata":{},"source":["IMPORTANT: You can set the preprocessing parameters in the `preprocessing_params.py` file.\n","\n","- COLAB: Set True if you are using Google Colab\n","- FIRST_RUN: Set True if you are running the notebook for the first time in Colab\n","- PLOT: If you want to visualize the plots of the provided images.\n","- MODEL_NAME: The name of the model you will found in saved_models/ folder.\n","\n","- VALIDATION_SET: If you want to use the validation set. Otherwise, the model will be trained on the whole dataset.\n","- VALIDATION_SPLIT: The proportion of the validation set.\n","\n","- TEST_SET: If you want to use a test set like the competition one.\n","- TEST_WINDOW: Window size of the test set.\n","- TEST_TELESCOPE: The number of timestamps to predict for each timeseries in the test set."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["COLAB = False\n","FIRST_RUN = True\n","PLOT = False\n","MODEL_NAME = \"ConvLSTMDenseComplex\"\n","\n","VALIDATION_SET = True\n","VAL_DIMENSION = 120 # must be a multiple of 60\n","\n","TF_DATASET = True"]},{"cell_type":"markdown","metadata":{},"source":["### Colab"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["if COLAB:\n","    if FIRST_RUN:\n","        ## Clone the private repository in Colab\n","        TOKEN = \"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\"\n","        REPO_URL= \"github.com/davide-gurrieri/timeseries-forecasting.git\"\n","        USER_NAME = \"davide-gurrieri\"\n","        USER_EMAIL = \"gurrieri99@gmail.com\"\n","\n","        !git clone --branch main https://oauth2:$TOKEN@$REPO_URL\n","        %cd timeseries-forecasting/\n","        !git remote set-url origin  https://oauth2:$TOKEN@$REPO_URL\n","        !git config user.name $USER_NAME\n","        !git config user.email $USER_EMAIL\n","        %cd ..\n","        \n","        # Import the data from the drive\n","        from google.colab import drive\n","        drive.mount('/content/drive')\n","        # Copy the data from the drive to the local repository folder\n","        %cp \"drive/MyDrive/[2023-2024] AN2DL/Homework 2/training_dataset.zip\" \"timeseries-forecasting/data/\"\n","        # Unzip the data\n","        !unzip timeseries-forecasting/data/training_dataset.zip -d timeseries-forecasting/data/\n","        # Remove the zip file\n","        !rm timeseries-forecasting/data/training_dataset.zip\n","        %cd timeseries-forecasting/\n","    else:\n","        %cd timeseries-forecasting/"]},{"cell_type":"markdown","metadata":{"id":"ap3o8JayfgEM"},"source":["### Import libraries"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2.14.0\n"]}],"source":["import models.ConvLSTMDense as MyModel\n","from models.ConvLSTMDense import ConvLSTMDense as Constructor"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from imports import *\n","from preprocessing_params import *\n","import utils"]},{"cell_type":"markdown","metadata":{},"source":["### Data processing"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["(48000, 2776)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["data = np.load(\"data/training_data.npy\")\n","data.shape"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["data = data.astype(np.float32)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Unique categories:\n","['A' 'B' 'C' 'D' 'E' 'F']\n"]}],"source":["categories = np.load(\"data/categories.npy\")\n","categories.shape\n","print(\"Unique categories:\")\n","print(np.unique(categories))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[2325 2776]\n"," [2325 2776]\n"," [2325 2776]\n"," [2712 2776]]\n","Min and max start time:  0 2752\n","Min and max end time:  2776 2776\n"]}],"source":["valid_periods = np.load(\"data/valid_periods.npy\")\n","valid_periods.shape\n","print(valid_periods[0:4,])\n","print(\"Min and max start time: \", min(valid_periods[:,0]), max(valid_periods[:,0]))\n","print(\"Min and max end time: \", min(valid_periods[:,1]), max(valid_periods[:,1]))"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Better to save the image and open the pdf to see all the details\n","if PLOT:\n","    utils.plot_matrix(data, save=True, show=True)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Better to save the images and open pdfs to see all the details\n","if PLOT:\n","    for category in np.unique(categories):\n","        utils.plot_matrix(data[categories == category], save=True, show=True, name=category)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of rows for each category:\n","A 5728\n","B 10987\n","C 10017\n","D 10016\n","E 10975\n","F 277\n"]}],"source":["# count the number of rows in each category\n","print(\"Number of rows for each category:\")\n","for category in np.unique(categories):\n","    print(category, np.sum(categories == category))"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["if PLOT:\n","    utils.plot_time_series(data, categories, category=\"A\", n=5)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X_val shape:  (120, 200, 1)\n","y_val shape:  (120, 18, 1)\n","data shape:  (47880, 2776)\n","categories shape:  (47880,)\n","valid_periods shape:  (47880, 2)\n"]}],"source":["if VALIDATION_SET:\n","    n_timeseries_per_category = VAL_DIMENSION // 6\n","    selected_indices = np.empty((0,)).astype(int)\n","    # take only the time series with at least TEST_WINDOW + TEST_TELESCOPE valid values\n","    valids = valid_periods[:,1] - valid_periods[:,0] > WINDOW + TELESCOPE\n","    for category in np.unique(categories):\n","        indices = np.logical_and(valids, categories == category)\n","        indices = np.where(indices)[0]\n","        indices = indices[np.random.choice(len(indices), n_timeseries_per_category, replace=False)]\n","        selected_indices = np.concatenate((selected_indices, indices))\n","\n","    X_val = data[selected_indices, -(WINDOW + TELESCOPE):-TELESCOPE]\n","    y_val = data[selected_indices, -TELESCOPE:]\n","    X_val = np.expand_dims(X_val, axis=-1)\n","    y_val = np.expand_dims(y_val, axis=-1)\n","    categories_val = categories[selected_indices]\n","    \n","    data = np.delete(data, selected_indices, axis=0)\n","    categories = np.delete(categories, selected_indices, axis=0)\n","    valid_periods = np.delete(valid_periods, selected_indices, axis=0)\n","    \n","    print(\"X_val shape: \", X_val.shape)\n","    print(\"y_val shape: \", y_val.shape)\n","    \n","    print(\"data shape: \", data.shape)\n","    print(\"categories shape: \", categories.shape)\n","    print(\"valid_periods shape: \", valid_periods.shape)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["if VALIDATION_SET and PLOT:\n","    utils.inspect_multivariate(X_val, y_val, TELESCOPE, idx=0, n=60)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(75283, 200, 1) (75283, 18, 1)\n"]}],"source":["# build sequences\n","X_train, y_train = utils.build_sequences_2(data, valid_periods, padding_type = \"constant\", min_len=54, repeat_first=True)\n","print(X_train.shape, y_train.shape)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# Tensorflow dataset creation\n","if TF_DATASET:\n","    AUTO = tf.data.experimental.AUTOTUNE\n","    BS=256\n","    tfds_val = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n","    tfds_val = tfds_val.batch(BS).prefetch(AUTO)\n","\n","tfds_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n","tfds_train = tfds_train.shuffle(1024).batch(BS).prefetch(AUTO)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"ConvLSTMDenseComplex\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," Input (InputLayer)          [(None, 200, 1)]          0         \n","                                                                 \n"," data_augmentation (DataAug  (None, 200, 1)            0         \n"," mentation)                                                      \n","                                                                 \n"," bidirectional_lstm (Bidire  (None, 200, 192)          75264     \n"," ctional)                                                        \n","                                                                 \n"," conv (Conv1D)               (None, 200, 64)           36928     \n","                                                                 \n"," flatten (Flatten)           (None, 12800)             0         \n","                                                                 \n"," Output (Dense)              (None, 18)                230418    \n","                                                                 \n","=================================================================\n","Total params: 342610 (1.31 MB)\n","Trainable params: 342610 (1.31 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model_obj = Constructor(MODEL_NAME,\n","                        MyModel.build_param_1,\n","                        MyModel.compile_param_1,\n","                        MyModel.fit_param_1,)\n","\n","model_obj.build()\n","model_obj.compile()\n","model_obj.model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if VALIDATION_SET:\n","    if TF_DATASET:\n","        model_obj.train_val(x_train = tfds_train, x_val = tfds_val)\n","    else:\n","        model_obj.train_val(X_train, y_train, X_val, y_val)\n","else:\n","    if TF_DATASET:\n","        model_obj.train(x_train = tfds_train)\n","    else:\n","        model_obj.train(X_train, y_train)"]},{"cell_type":"markdown","metadata":{},"source":["Save the model as `saved_model/MODEL_NAME` and also in the drive (Colab case)."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["model_obj.save_model()\n","if COLAB:\n","    %cd ..\n","    %cp -r \"/content/timeseries-forecasting/saved_models/MODEL_NAME\" \"drive/MyDrive/\"\n","    %cd timeseries-forecasting/"]},{"cell_type":"markdown","metadata":{},"source":["### Performance evaluation"]},{"cell_type":"markdown","metadata":{},"source":["Plot the training history"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if VALIDATION_SET:\n","    model_obj.plot_history()"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate the model on the validation set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if VALIDATION_SET:\n","    model_obj.evaluate(X_val, y_val)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
